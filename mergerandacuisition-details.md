# M&A Prediction Platform Details

## 1️⃣ Data Ingestion (Raw / Bronze Layer)

**Source:** Reuters Financial News API

### Data Types Considered:

| Field             | Description            | Notes / ETL Considerations                                      |
|-------------------|------------------------|-----------------------------------------------------------------|
| headline          | News headline text     | Always ingested; initial deduplication applied                 |
| body              | Full article text      | Filter out very short or malformed entries (<50 chars)         |
| publication_date  | Timestamp              | Partitioned by date in Bronze layer                            |
| company_mentions  | Named entities         | Extracted with NER during ETL                                  |
| source            | News provider          | Used for reliability scoring                                   |
| article_id        | Unique identifier      | Deduplicated against prior ingestion                           |

### Initial Filtering Example (ETL Rules):
- Discard articles not mentioning companies in target universe
- Remove entries older than 2 years for initial rolling window
- Filter out non-English content
- Remove duplicated or malformed entries
- Retain only articles flagged as financial/corporate news (category filter)

---

## 2️⃣ Label Generation (Supervised Dataset)

To fine-tune BERT for M&A prediction, the system required labeled data. Labels were generated by combining historical M&A events with text content.

### Labels Derived:

| Label          | Source / Rule                     | Description                                                   |
|----------------|-----------------------------------|---------------------------------------------------------------|
| acquisition    | M&A transaction logs             | 1 if article mentions an acquisition confirmed in historical data |
| merger         | Historical merger announcements  | 1 if article describes a merger event                        |
| stake_purchase | SEC filings or company disclosures| 1 if article describes strategic shareholding                |
| no_event       | Default                           | 0 if none of the above applied                               |

### ETL Labeling Workflow Example:
1. Parse article → tokenize + NER to detect companies/entities
2. Cross-reference publication date with historical events table
3. Assign labels (acquisition, merger, stake_purchase)
4. Articles not matched to historical events → no_event
5. Store labeled dataset in Silver Layer (cleaned, tokenized, ML-ready)

---

## 3️⃣ Feature Engineering for BERT

### Text Features Extracted:
- Tokenized headline + article body
- Named entity mentions: companies, executives, regulators
- Sentiment score (positive/negative/neutral) using preliminary NLP lexicon
- Dependency parsing for relationship extraction (who is buying/selling)
- Contextual embeddings generated with BERT tokenizer

### Optional Additional Features:
- Frequency of company mentions per article
- Co-occurrence of multiple companies in same article
- Temporal features: rolling averages of sentiment over last 7/30 days

---

## 4️⃣ BERT Model & Prediction Output

### Model Used:
- Google BERT base uncased (pre-trained)
- Fine-tuned with historical financial event dataset
- Input: tokenized articles with company entity embeddings
- Output: classification probabilities

### Predictions Generated:

| Output Field      | Description                                      |
|-------------------|--------------------------------------------------|
| event_type        | Predicted label (acquisition, merger, stake_purchase, no_event) |
| probability       | Confidence score (0–1) of the event occurring    |
| confidence        | Model certainty; used for thresholding and alerts |
| entity_pair       | Company or company pair referenced               |
| prediction_date   | Timestamp for inference                          |
| rolling_sentiment | Optional derived feature from historical articles|

### Example Use Case:

**Article:** “TechCorp announces intention to acquire StartUpX for $500M”

**BERT Output:**
```json
{
  "entity_pair": ["TechCorp", "StartUpX"],
  "event_type": "acquisition",
  "probability": 0.87,
  "confidence": 0.92,
  "prediction_date": "2025-06-15T10:00:00Z"
}
```

---

## ✅ Summary of ETL-to-BERT Flow

1. **Ingestion (Bronze):** Pull raw articles from Reuters, deduplicate, partition
2. **Filtering & Cleaning (Silver):** Remove irrelevant or malformed articles, normalize text, extract entities
3. **Labeling:** Map historical M&A events to articles for supervised training
4. **Feature Engineering:** Tokenization, embeddings, entity co-occurrence, sentiment
5. **ML Layer (Gold):** BERT fine-tuning → probability scores → output stored in Gold layer for analytics

---

If needed, I can create a visual “ETL + BERT pipeline diagram” to illustrate:
- Raw ingestion → filtering → labeled Silver → feature engineering → BERT → Gold predictions

This would be ideal for senior architecture or design review presentations.